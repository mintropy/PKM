---

type : knowledges
detail : Image Detection
content_type : paper
annotation-target: You Only Loock Once.pdf

---

[[AI]]
**tags** : #ðŸ–¥ï¸Note/AI/Paper 

>%%
>```annotation-json
>{"text":"Abstract","target":[{"source":"vault:/notes/AI/files/You Only Loock Once.pdf","selector":[{"type":"TextPositionSelector","start":216,"end":224},{"type":"TextQuoteSelector","exact":"Abstract","prefix":"searchÂ¶http://pjreddie.com/yolo/","suffix":"We present YOLO, a new approach"}]}],"created":"2022-03-08T06:40:35.378Z","updated":"2022-03-08T06:40:35.378Z","document":{"title":"You Only Loock Once.pdf","link":[{"href":"urn:x-pdf:6742b0a02d8cab19dfef85ebfc90ade6"},{"href":"vault:/notes/AI/files/You Only Loock Once.pdf"}],"documentFingerprint":"6742b0a02d8cab19dfef85ebfc90ade6"},"uri":"vault:/notes/AI/files/You Only Loock Once.pdf"}
>```
>%%
>*%%PREFIX%%searchÂ¶http://pjreddie.com/yolo/%%HIGHLIGHT%% ==Abstract== %%POSTFIX%%We present YOLO, a new approach*
>%%LINK%%[[#^hga47elcrm4|show annotation]]
>%%COMMENT%%
>Abstract
>%%TAGS%%
>
^hga47elcrm4


>%%
>```annotation-json
>{"created":"2022-03-08T06:45:44.612Z","updated":"2022-03-08T06:45:44.612Z","document":{"title":"You Only Loock Once.pdf","link":[{"href":"urn:x-pdf:6742b0a02d8cab19dfef85ebfc90ade6"},{"href":"vault:/notes/AI/files/You Only Loock Once.pdf"}],"documentFingerprint":"6742b0a02d8cab19dfef85ebfc90ade6"},"uri":"vault:/notes/AI/files/You Only Loock Once.pdf","target":[{"source":"vault:/notes/AI/files/You Only Loock Once.pdf","selector":[{"type":"TextPositionSelector","start":362,"end":486},{"type":"TextQuoteSelector","exact":"we frame object detection as a re-gression problem to spatially separated bounding boxes andassociated class probabilities. ","prefix":"to per-form detection. Instead, ","suffix":"A single neural network pre-dict"}]}]}
>```
>%%
>*%%PREFIX%%to per-form detection. Instead,%%HIGHLIGHT%% ==we frame object detection as a re-gression problem to spatially separated bounding boxes andassociated class probabilities.== %%POSTFIX%%A single neural network pre-dict*
>%%LINK%%[[#^frn5tpyegpu|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^frn5tpyegpu


>%%
>```annotation-json
>{"created":"2022-03-08T06:46:12.664Z","updated":"2022-03-08T06:46:12.664Z","document":{"title":"You Only Loock Once.pdf","link":[{"href":"urn:x-pdf:6742b0a02d8cab19dfef85ebfc90ade6"},{"href":"vault:/notes/AI/files/You Only Loock Once.pdf"}],"documentFingerprint":"6742b0a02d8cab19dfef85ebfc90ade6"},"uri":"vault:/notes/AI/files/You Only Loock Once.pdf","target":[{"source":"vault:/notes/AI/files/You Only Loock Once.pdf","selector":[{"type":"TextPositionSelector","start":603,"end":722},{"type":"TextQuoteSelector","exact":"Since the whole detectionpipeline is a single network, it can be optimized end-to-enddirectly on detection performance.","prefix":"mfull images in one evaluation. ","suffix":"Our unified architecture is extr"}]}]}
>```
>%%
>*%%PREFIX%%mfull images in one evaluation.%%HIGHLIGHT%% ==Since the whole detectionpipeline is a single network, it can be optimized end-to-enddirectly on detection performance.== %%POSTFIX%%Our unified architecture is extr*
>%%LINK%%[[#^8jz9qfy3a3y|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^8jz9qfy3a3y


>%%
>```annotation-json
>{"text":"1. Introduction","target":[{"source":"vault:/notes/AI/files/You Only Loock Once.pdf","selector":[{"type":"TextPositionSelector","start":1335,"end":1350},{"type":"TextQuoteSelector","exact":"1. Introduction","prefix":"s to other domains like artwork.","suffix":"Humans glance at an image and in"}]}],"created":"2022-03-08T06:48:20.524Z","updated":"2022-03-08T06:48:20.524Z","document":{"title":"You Only Loock Once.pdf","link":[{"href":"urn:x-pdf:6742b0a02d8cab19dfef85ebfc90ade6"},{"href":"vault:/notes/AI/files/You Only Loock Once.pdf"}],"documentFingerprint":"6742b0a02d8cab19dfef85ebfc90ade6"},"uri":"vault:/notes/AI/files/You Only Loock Once.pdf"}
>```
>%%
>*%%PREFIX%%s to other domains like artwork.%%HIGHLIGHT%% ==1. Introduction== %%POSTFIX%%Humans glance at an image and in*
>%%LINK%%[[#^2myepg6djti|show annotation]]
>%%COMMENT%%
>1. Introduction
>%%TAGS%%
>
^2myepg6djti


>%%
>```annotation-json
>{"created":"2022-03-08T06:51:23.833Z","updated":"2022-03-08T06:51:23.833Z","document":{"title":"You Only Loock Once.pdf","link":[{"href":"urn:x-pdf:6742b0a02d8cab19dfef85ebfc90ade6"},{"href":"vault:/notes/AI/files/You Only Loock Once.pdf"}],"documentFingerprint":"6742b0a02d8cab19dfef85ebfc90ade6"},"uri":"vault:/notes/AI/files/You Only Loock Once.pdf","target":[{"source":"vault:/notes/AI/files/You Only Loock Once.pdf","selector":[{"type":"TextPositionSelector","start":1471,"end":1550},{"type":"TextQuoteSelector","exact":"human visual system is fast and accurate, allow-ing us to perform complex tasks","prefix":"re, and how they inter-act. The ","suffix":" like driving with little con-sc"}]}]}
>```
>%%
>*%%PREFIX%%re, and how they inter-act. The%%HIGHLIGHT%% ==human visual system is fast and accurate, allow-ing us to perform complex tasks== %%POSTFIX%%like driving with little con-sc*
>%%LINK%%[[#^z5rnghpdbi|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^z5rnghpdbi


>%%
>```annotation-json
>{"created":"2022-03-08T06:56:05.079Z","updated":"2022-03-08T06:56:05.079Z","document":{"title":"You Only Loock Once.pdf","link":[{"href":"urn:x-pdf:6742b0a02d8cab19dfef85ebfc90ade6"},{"href":"vault:/notes/AI/files/You Only Loock Once.pdf"}],"documentFingerprint":"6742b0a02d8cab19dfef85ebfc90ade6"},"uri":"vault:/notes/AI/files/You Only Loock Once.pdf","target":[{"source":"vault:/notes/AI/files/You Only Loock Once.pdf","selector":[{"type":"TextPositionSelector","start":1860,"end":1930},{"type":"TextQuoteSelector","exact":"Current detection systems repurpose classifiers to per-form detection.","prefix":"ose, responsive robotic systems.","suffix":" To detect an object, these syst"}]}]}
>```
>%%
>*%%PREFIX%%ose, responsive robotic systems.%%HIGHLIGHT%% ==Current detection systems repurpose classifiers to per-form detection.== %%POSTFIX%%To detect an object, these syst*
>%%LINK%%[[#^2yk2ufpnptw|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^2yk2ufpnptw
